{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) K-means Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.93308846886234 dB\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "src = cv2.imread(\"../data/lena.png\").astype(np.float32)/255\n",
    "\n",
    "data = src.reshape(-1, 3)\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 10, 0.001)\n",
    "\n",
    "retval, labels, centers = cv2.kmeans(data, 64, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "centers = centers.clip(0,1)\n",
    "\n",
    "dst = centers[labels].reshape(src.shape)\n",
    "\n",
    "print('{} dB'.format(cv2.PSNR(src, dst,1)))\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lab Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.91326470853884 dB\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"../data/lena.png\").astype(np.float32)/255\n",
    "image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "data = image_lab.reshape(-1, 3)\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 10, 0.001)\n",
    "\n",
    "retval, labels, centers = cv2.kmeans(data, 64, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "dst = centers[labels].reshape(image.shape)\n",
    "recon = cv2.cvtColor(dst,cv2.COLOR_Lab2BGR)\n",
    "recon = recon.clip(0,1)\n",
    "\n",
    "print('{} dB'.format(cv2.PSNR(image, recon,1)))\n",
    "\n",
    "cv2.imshow(\"reconstucted image\", recon)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HSV Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.144032688932764 dB\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"../data/lena.png\").astype(np.float32)/255\n",
    "image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "data = image_hsv.reshape(-1, 3)\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 10, 0.001)\n",
    "\n",
    "retval, labels, centers = cv2.kmeans(data, 64, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "dst = centers[labels].reshape(image.shape)\n",
    "recon = cv2.cvtColor(dst,cv2.COLOR_HSV2BGR)\n",
    "recon = recon.clip(0,1)\n",
    "\n",
    "print('{} dB'.format(cv2.PSNR(image, recon,1)))\n",
    "\n",
    "cv2.imshow(\"reconstucted image\", recon)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Vector Quantization using K-Means Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "압축율 : 30.12 : 1\n",
      "비트레이트: 0.80 bpp\n",
      "복원화질: 27.032521445433492 dB\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "src = cv2.imread(\"../data/lena.png\").astype(np.float32)/255\n",
    "\n",
    "pels = src.shape[0]*src.shape[1]\n",
    "n = 8\n",
    "\n",
    "data = src.reshape(-1, 3)\n",
    "data = data.reshape((pels//n, n, 3))\n",
    "data = data.reshape((pels//n,-1))\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 10, 0.001)\n",
    "\n",
    "retval, labels, centers = cv2.kmeans(data, 64, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "centers = centers.clip(0,1)\n",
    "\n",
    "dst = centers[labels].reshape(-1,3)\n",
    "dst = dst.reshape(image.shape)\n",
    "\n",
    "k = 64*n*24 + (pels//n)*6\n",
    "t = image.shape[0] * image.shape[1] * 24\n",
    "print('압축율 : {:0.2f} : 1'.format(t/k))\n",
    "print('비트레이트: {:0.2f} bpp'.format(k/pels))\n",
    "print('복원화질: {} dB'.format(cv2.PSNR(src, dst,1)))\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Distance transform\n",
    "- 화소마다 자신의 위치에서 배경 (0 레벨인 화소 집합) 까지의 거리를 구한다.\n",
    "- 배경에 포함된 화소의 거리는 0으로 한다.\n",
    "- 오브젝트 내에서 이 거리가 가장 먼 점과 가장 가까운 점을 어떻게 활용할 수 있을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640) float32 0.0 190.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = np.full((480, 640), 255, np.uint8)\n",
    "image = cv2.rectangle(image, (200, 0), (500, 480), 0, 20)\n",
    "\n",
    "distmap = cv2.distanceTransform(image, cv2.DIST_L2, cv2.DIST_MASK_PRECISE)\n",
    "print(distmap.shape, distmap.dtype, distmap.min(), distmap.max())\n",
    "\n",
    "cv2.imshow('image', image)\n",
    "cv2.imshow('distancemap', cv2.normalize(distmap,None,0,1,cv2.NORM_MINMAX))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### (4) Watershed Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('../data/water_coins.jpg')\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "blur = cv.GaussianBlur(gray, (7,7), 0)\n",
    "_, mask = cv.threshold(blur,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
    "\n",
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv.morphologyEx(mask,cv.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# 강제 확장된 foreground\n",
    "ext_fg = cv.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "# Finding sure foreground area\n",
    "# 배경과의 거리가 최대값의 80% 이상인 화소들만 남긴다\n",
    "dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "_, sure_fg = cv.threshold(dist_transform,0.8*dist_transform.max(),255,cv2.THRESH_BINARY)\n",
    "\n",
    "# Finding unknown region\n",
    "# 영역 확장에서 sure_fg를 제외한 영역\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv.subtract(ext_fg, sure_fg)\n",
    "\n",
    "# Marker labelling of sure_fg\n",
    "ret, markers = cv.connectedComponents(sure_fg)\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers + 1\n",
    "# Now, mark the region of unknown with zero\n",
    "# marker for the sure_bg is 1\n",
    "# markers for objects are 2..markers.max()\n",
    "markers[unknown==255] = 0\n",
    "# marker가 0인 화소들의 marker를 새로 할당한다.\n",
    "# 경계선에 존재하는 화소들은 marker 값을 -1로 한다.\n",
    "markers = cv.watershed(img, markers)\n",
    "img[markers == -1] = [0,255,255]\n",
    "\n",
    "cv2.imshow('images with boundaries', img)\n",
    "cv2.imshow('markers', (markers*15).astype(np.uint8))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "10340f3b4385e401792eeb44b8b5edca2cd8c002c17926bde515355c1d6e3c5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
